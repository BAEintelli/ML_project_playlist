{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T10:24:23.613429Z",
     "start_time": "2020-06-05T10:24:21.683423Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T10:24:30.031483Z",
     "start_time": "2020-06-05T10:24:23.634524Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_tr = pd.read_json(\"./raw_data/train.json\")\n",
    "raw_te = pd.read_json(\"./태그, 노래 채우기/validation.json\")\n",
    "# raw_te = pd.read_json(\"./raw_data/val.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 코사인 유사도 행렬 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  step1. playlist X tag binary matrix 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T10:24:30.988573Z",
     "start_time": "2020-06-05T10:24:30.045885Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "test_df = pd.concat([raw_tr])\n",
    "raw_te_tags_mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "raw_te_tags = list(test_df.tags)\n",
    "te_tag_df = raw_te_tags_mlb.fit_transform(raw_te_tags)\n",
    "te_tag_classes = raw_te_tags_mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T10:24:32.751854Z",
     "start_time": "2020-06-05T10:24:30.992938Z"
    }
   },
   "outputs": [],
   "source": [
    "data_items = pd.DataFrame(te_tag_df.todense(), columns=te_tag_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T10:29:16.073742Z",
     "start_time": "2020-06-05T10:24:32.761490Z"
    }
   },
   "outputs": [],
   "source": [
    "#------------------------\n",
    "# ITEM-ITEM CALCULATIONS\n",
    "#------------------------\n",
    "\n",
    "# magnitude = sqrt(x2 + y2 + z2 + ...)\n",
    "magnitude = np.sqrt(np.square(data_items).sum(axis=1))\n",
    "\n",
    "# vector = (x / magnitude, y / magnitude, z / magnitude, ...)\n",
    "data_items = data_items.divide(magnitude, axis='index')\n",
    "\n",
    "def calculate_similarity(data_items):\n",
    "    data_sparse = sparse.csr_matrix(data_items)\n",
    "    similarities = cosine_similarity(data_sparse.transpose())\n",
    "    sim = pd.DataFrame(data=similarities, index= data_items.columns, \n",
    "                       columns = data_items.columns)\n",
    "    return sim\n",
    "\n",
    "# Build the similarity matrix\n",
    "data_matrix = calculate_similarity(data_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T10:29:16.133404Z",
     "start_time": "2020-06-05T10:29:16.103751Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_similar_tags_top10(tags):\n",
    "    return data_matrix.index[np.argsort(data_matrix.loc[tags[0]].values)[::-1][:10]].tolist()\n",
    "# list(itertools.chain([i[: 10 // len(tags)+1] for i in ls]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T10:29:16.165942Z",
     "start_time": "2020-06-05T10:29:16.149630Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_similar_tags(tags):\n",
    "    from collections import OrderedDict\n",
    "    from itertools import repeat\n",
    "    ls = []\n",
    "    for tag in tags:        \n",
    "        ls += list(OrderedDict(zip(data_matrix.index[np.argsort(data_matrix.loc[tag].values)[::-1]].tolist(), repeat(None))))[:int(10/len(tags))]\n",
    "    return ls[:10]\n",
    "# list(itertools.chain([i[: 10 // len(tags)+1] for i in ls]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T10:29:16.851577Z",
     "start_time": "2020-06-05T10:29:16.185370Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T11:02:25.281558Z",
     "start_time": "2020-06-05T11:02:08.090911Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23015/23015 [00:17<00:00, 1339.45it/s]\n"
     ]
    }
   ],
   "source": [
    "tag_ret = raw_te.tags.progress_apply(lambda x : get_similar_tags_top10(x)).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## playlist X songs list in list 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T11:02:33.662339Z",
     "start_time": "2020-06-05T11:02:33.615399Z"
    }
   },
   "outputs": [],
   "source": [
    "from implicit.evaluation import  *\n",
    "from implicit.als import AlternatingLeastSquares as ALS\n",
    "from implicit.bpr import BayesianPersonalizedRanking as BPR\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "from sklearn.utils import shuffle\n",
    "from scipy.sparse import *\n",
    "# import rec_util\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.2f}'.format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T11:02:37.802457Z",
     "start_time": "2020-06-05T11:02:33.942824Z"
    }
   },
   "outputs": [],
   "source": [
    "train_songs = raw_tr['songs'].tolist()\n",
    "test_songs = raw_te['songs'].apply(lambda x : [float(i)for i in x]).tolist()\n",
    "train_tags = raw_tr['tags'].tolist()\n",
    "test_tags = raw_te['tags'].tolist()\n",
    "test_ids = raw_te['id'].tolist()\n",
    "\n",
    "### train 데이터 list to list 로 만들기\n",
    "\n",
    "from itertools import groupby\n",
    "tr = []\n",
    "iid_to_idx = {}\n",
    "idx = 0\n",
    "\n",
    "for i, l in enumerate(train_songs):\n",
    "    view = l\n",
    "    for item_id in view:\n",
    "        if item_id not in iid_to_idx:\n",
    "            iid_to_idx[item_id] = idx\n",
    "            idx += 1\n",
    "    view = [iid_to_idx[x] for x in view]\n",
    "    tr.append(view)\n",
    "\n",
    "idx = 0\n",
    "n_items = 615142\n",
    "tag_to_idx = {} \n",
    "for i, tags in enumerate(train_tags):\n",
    "    for tag in tags:\n",
    "        if tag not in tag_to_idx:\n",
    "            tag_to_idx[tag] = n_items + idx\n",
    "            idx += 1\n",
    "    tr[i].extend([tag_to_idx[x] for x in tags])\n",
    "n_items = len(iid_to_idx)\n",
    "n_tags = len(tag_to_idx)\n",
    "\n",
    "### test 데이터 list to list 로 만들기\n",
    "\n",
    "te = []\n",
    "\n",
    "idx = 0\n",
    "for i, l in enumerate(test_songs):\n",
    "    view = l\n",
    "    ret = [] \n",
    "    for item_id in view:\n",
    "        if item_id not in iid_to_idx:\n",
    "            continue\n",
    "        ret.append(iid_to_idx[item_id])\n",
    "    te.append(ret)\n",
    "idx = 0\n",
    "for i, tags in enumerate(test_tags):\n",
    "    ret = []\n",
    "    for tag in tags:\n",
    "        if tag not in tag_to_idx:\n",
    "            continue\n",
    "        ret.append(tag)\n",
    "    te[i].extend([tag_to_idx[x] for x in ret])\n",
    "\n",
    "# 데이터 쓰까\n",
    "\n",
    "tr = shuffle(tr, random_state=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 노래 및 태그 인덱싱 하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T11:02:37.878871Z",
     "start_time": "2020-06-05T11:02:37.804649Z"
    }
   },
   "outputs": [],
   "source": [
    "idx_to_iid = {x:y for(y,x) in iid_to_idx.items()}\n",
    "idx_to_tag = {(x - n_items):y for(y,x) in tag_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T11:02:43.207899Z",
     "start_time": "2020-06-05T11:02:37.881335Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(tokenizer=lambda x: x, lowercase=False)\n",
    "tr_array = cv.fit_transform(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T11:02:44.057482Z",
     "start_time": "2020-06-05T11:02:43.210197Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(tokenizer=lambda x: x, lowercase=False)\n",
    "te_array = cv.fit_transform(te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T11:02:44.062880Z",
     "start_time": "2020-06-05T11:02:44.059566Z"
    }
   },
   "outputs": [],
   "source": [
    "tr_csr = csr_matrix(tr_array, (len(tr), n_items))\n",
    "te_csr = csr_matrix(te_array, (len(te), n_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T11:02:44.096555Z",
     "start_time": "2020-06-05T11:02:44.065275Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<138086x615142 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6296707 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.sparse\n",
    "r = scipy.sparse.vstack([tr_csr,te_csr])\n",
    "r = csr_matrix(r)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALS 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T11:04:55.259697Z",
     "start_time": "2020-06-05T11:03:16.040095Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Intel MKL BLAS detected. Its highly recommend to set the environment variable 'export MKL_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d59881b5782f42f6a2401571fa69a5f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "als_model = ALS(factors=256, regularization=0.01, iterations=5, calculate_training_loss=True)\n",
    "als_model.fit(r.T * 15.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T11:04:55.267076Z",
     "start_time": "2020-06-05T11:04:55.262803Z"
    }
   },
   "outputs": [],
   "source": [
    "item_model = ALS(use_gpu=False)\n",
    "# tag_model = ALS(use_gpu=False)\n",
    "item_model.user_factors = als_model.user_factors\n",
    "# tag_model.user_factors = als_model.user_factors\n",
    "\n",
    "item_model.item_factors = als_model.item_factors\n",
    "# tag_model.item_factors = als_model.item_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T11:04:55.282953Z",
     "start_time": "2020-06-05T11:04:55.271097Z"
    }
   },
   "outputs": [],
   "source": [
    "item_rec_csr = tr_csr[:, :n_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T02:19:17.518922Z",
     "start_time": "2020-05-28T02:19:17.516408Z"
    }
   },
   "outputs": [],
   "source": [
    "# item_rec_csr = te_tag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T11:19:34.430320Z",
     "start_time": "2020-06-05T11:06:01.149419Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff645af7cac1483391668aff11759dff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=23015), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "item_ret = []\n",
    "# tag_ret = []\n",
    "from tqdm.auto import tqdm\n",
    "for u in tqdm(range(te_csr.shape[0])):\n",
    "    item_rec = item_model.recommend(u, item_rec_csr, N=100)\n",
    "    item_rec = [idx_to_iid[x[0]] for x in item_rec]\n",
    "    # tag_rec = tag_model.recommend(u, tag_rec_csr, N=100)\n",
    "    # tag_rec = [idx_to_tag[x[0]] for x in tag_rec if x[0] in idx_to_tag]\n",
    "    item_ret.append(item_rec)\n",
    "    # tag_ret.append(tag_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T11:19:34.443806Z",
     "start_time": "2020-06-05T11:19:34.432500Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(item_ret)):\n",
    "    if len(item_ret[i]) != 100:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T11:19:34.469777Z",
     "start_time": "2020-06-05T11:19:34.446832Z"
    }
   },
   "outputs": [],
   "source": [
    "# 태그 중복 확인\n",
    "check_list = []\n",
    "for tags in tag_ret:\n",
    "    if len(set(tags)) != 10:\n",
    "        print(len(set(tags)))\n",
    "        check_list.append(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제출용 json 파일 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T11:19:34.582781Z",
     "start_time": "2020-06-05T11:19:34.472501Z"
    }
   },
   "outputs": [],
   "source": [
    "returnval = []\n",
    "for _id, rec, tag_rec in zip(test_ids, item_ret, tag_ret):\n",
    "    returnval.append({\n",
    "        \"id\": _id,\n",
    "        \"songs\": rec[:100],\n",
    "        \"tags\": tag_rec[:10]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T11:19:35.165365Z",
     "start_time": "2020-06-05T11:19:34.584534Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('results.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(returnval, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
